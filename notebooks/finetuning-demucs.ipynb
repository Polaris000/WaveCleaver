{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8394662,"sourceType":"datasetVersion","datasetId":4993932},{"sourceId":8394680,"sourceType":"datasetVersion","datasetId":4993944}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchaudio\n\nprint(torch.__version__)\nprint(torchaudio.__version__)\n\nimport matplotlib.pyplot as plt\n","metadata":{"id":"HViOBbYDtCm8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9eb2ed66-6953-4573-eff5-684ff0e9bfbc","execution":{"iopub.status.busy":"2024-05-12T20:55:22.393656Z","iopub.execute_input":"2024-05-12T20:55:22.394009Z","iopub.status.idle":"2024-05-12T20:55:26.122351Z","shell.execute_reply.started":"2024-05-12T20:55:22.393980Z","shell.execute_reply":"2024-05-12T20:55:26.121416Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"2.1.2\n2.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install mir_eval","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DeA0F8qtXUB","outputId":"908881f3-50bb-4b73-ad37-067306d34f2d","execution":{"iopub.status.busy":"2024-05-12T20:55:26.123850Z","iopub.execute_input":"2024-05-12T20:55:26.124262Z","iopub.status.idle":"2024-05-12T20:55:41.736455Z","shell.execute_reply.started":"2024-05-12T20:55:26.124236Z","shell.execute_reply":"2024-05-12T20:55:41.735274Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting mir_eval\n  Downloading mir_eval-0.7.tar.gz (90 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m897.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from mir_eval) (1.26.4)\nRequirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from mir_eval) (1.11.4)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from mir_eval) (1.0.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from mir_eval) (1.16.0)\nBuilding wheels for collected packages: mir_eval\n  Building wheel for mir_eval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for mir_eval: filename=mir_eval-0.7-py3-none-any.whl size=100701 sha256=d5eb88f0c22c93d44e98b72a15b3a6bb88fc32ddfc85f2b10af6e91cd0a1f482\n  Stored in directory: /root/.cache/pip/wheels/3e/2f/0d/dda9c4c77a170e21356b6afa2f7d9bb078338634ba05d94e3f\nSuccessfully built mir_eval\nInstalling collected packages: mir_eval\nSuccessfully installed mir_eval-0.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import Audio\nfrom mir_eval import separation\nfrom torchaudio.pipelines import HDEMUCS_HIGH_MUSDB_PLUS\nfrom torchaudio.utils import download_asset","metadata":{"id":"8aW3oP2ytCm_","execution":{"iopub.status.busy":"2024-05-12T20:55:44.624685Z","iopub.execute_input":"2024-05-12T20:55:44.625063Z","iopub.status.idle":"2024-05-12T20:55:45.584019Z","shell.execute_reply.started":"2024-05-12T20:55:44.625030Z","shell.execute_reply":"2024-05-12T20:55:45.583138Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"bundle = HDEMUCS_HIGH_MUSDB_PLUS\n\nmodel = bundle.get_model()\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nlast_layer = list(model.children())[-1]  \nsecond_last_layer = list(model.children())[-2]  \n\nfor param in model.parameters():\n    param.requires_grad = False\n    \nfor param in last_layer.parameters():\n    param.requires_grad = True\nfor param in second_last_layer.parameters():\n    param.requires_grad = True\n\nmodel.to(device)\nsample_rate = bundle.sample_rate\n\nprint(f\"Sample rate: {sample_rate}\")","metadata":{"id":"AX4LqLaitCnA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"44af0064-a9d5-451f-bfb1-0357ea581ef3","execution":{"iopub.status.busy":"2024-05-12T20:57:51.734006Z","iopub.execute_input":"2024-05-12T20:57:51.734786Z","iopub.status.idle":"2024-05-12T20:57:54.750470Z","shell.execute_reply.started":"2024-05-12T20:57:51.734755Z","shell.execute_reply":"2024-05-12T20:57:54.749504Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"100%|██████████| 319M/319M [00:01<00:00, 273MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"Sample rate: 44100\n","output_type":"stream"}]},{"cell_type":"code","source":"input_directory = '/kaggle/input/noisy-trainset-28spk-wav/noisy_trainset_28spk_wav'\ntarget_directory = '/kaggle/input/clean-trainset-28spk-wav/clean_trainset_28spk_wav'","metadata":{"id":"oh7wztniyGER","execution":{"iopub.status.busy":"2024-05-12T20:57:57.153158Z","iopub.execute_input":"2024-05-12T20:57:57.153486Z","iopub.status.idle":"2024-05-12T20:57:57.157904Z","shell.execute_reply.started":"2024-05-12T20:57:57.153461Z","shell.execute_reply":"2024-05-12T20:57:57.156910Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchaudio\nimport os\n\nclass AudioDataset(torch.utils.data.Dataset):\n    def __init__(self, input_directory, target_directory, target_length):\n        self.input_file_paths = [os.path.join(input_directory, filename) for filename in os.listdir(input_directory) if filename.endswith('.wav')]\n        self.target_file_paths = [os.path.join(target_directory, filename) for filename in os.listdir(target_directory) if filename.endswith('.wav')]\n        self.target_length = target_length\n        self.resample = torchaudio.transforms.Resample(orig_freq=44100, new_freq=target_length)\n\n    def __len__(self):\n        return len(self.input_file_paths)\n\n    def __getitem__(self, idx):\n        input_file_path = self.input_file_paths[idx]\n        target_file_path = self.target_file_paths[idx % len(self.target_file_paths)]\n\n        input_waveform, _ = torchaudio.load(input_file_path)\n        input_waveform = self.resample(input_waveform)\n\n        target_waveform, _ = torchaudio.load(target_file_path)\n        target_waveform = self.resample(target_waveform)\n\n        input_waveform = self.prepare_waveform(input_waveform)\n        target_waveform = self.prepare_waveform(target_waveform)\n\n        input_waveform_dual = torch.stack([input_waveform, input_waveform])\n        target_waveform_dual = torch.stack([target_waveform, target_waveform])\n\n        return input_waveform_dual, target_waveform_dual\n\n    def prepare_waveform(self, waveform):\n        if waveform.size(1) < self.target_length:\n            waveform = torch.nn.functional.pad(waveform, (0, self.target_length - waveform.size(1)))\n        elif waveform.size(1) > self.target_length:\n            waveform = waveform[:, :self.target_length]\n        return waveform\n\n\n\ntarget_length = 16000 \n \n\ndataset = AudioDataset(input_directory, target_directory, target_length)\n\n","metadata":{"id":"6QE2p3JzluRy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"23eb0794-82b0-4adb-8bef-ac72d3005926","execution":{"iopub.status.busy":"2024-05-12T20:57:58.003866Z","iopub.execute_input":"2024-05-12T20:57:58.004227Z","iopub.status.idle":"2024-05-12T20:57:58.127771Z","shell.execute_reply.started":"2024-05-12T20:57:58.004201Z","shell.execute_reply":"2024-05-12T20:57:58.127020Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"target_length = 160000\nbatch_size = 16\nnum_epochs = 10\n\n\ndataset = AudioDataset(input_directory, target_directory, target_length=target_length)\ndata_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","metadata":{"id":"GJqZGXl7p5mo","execution":{"iopub.status.busy":"2024-05-12T20:57:58.719488Z","iopub.execute_input":"2024-05-12T20:57:58.720296Z","iopub.status.idle":"2024-05-12T20:57:58.737315Z","shell.execute_reply.started":"2024-05-12T20:57:58.720264Z","shell.execute_reply":"2024-05-12T20:57:58.736504Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T20:57:59.601368Z","iopub.execute_input":"2024-05-12T20:57:59.601726Z","iopub.status.idle":"2024-05-12T20:57:59.606003Z","shell.execute_reply.started":"2024-05-12T20:57:59.601697Z","shell.execute_reply":"2024-05-12T20:57:59.605073Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchaudio.transforms import Resample\n\n\nloss_function = nn.MSELoss()\nnum_epochs = 10\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0.0\n\n    for input_batch, target_batch in data_loader:\n        input_batch = input_batch.squeeze(2)\n        input_batch = input_batch.to(device)\n        target_batch = target_batch.squeeze(2)\n        target_batch = target_batch.to(device)\n\n        output_batch = model(input_batch)\n        output_batch = output_batch[2, :, :,:]\n\n\n#         loss = loss_function(output_batch, target_batch)\n\n        sdr_loss = 0.0\n        for i in range(output_batch.shape[0]):\n            reference_sources = target_batch[i].cpu().numpy()\n            estimated_sources = output_batch[i].detach().cpu().numpy()\n#             estimated_sources = estimated_sources[2, :, : ]\n\n            sdr, _, _, _ = separation.bss_eval_sources(reference_sources, estimated_sources)\n\n            sdr_loss += sdr.mean()\n        sdr_loss /= output_batch.shape[0]\n\n        optimizer.zero_grad()\n#         loss.backward()\n        optimizer.step()\n\n#         total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}, Average SDR Loss: {sdr_loss/len(data_loader)}\")","metadata":{"id":"vSFRyIRzk9vu","colab":{"base_uri":"https://localhost:8080/","height":356},"outputId":"84ca0671-441f-43d7-831c-9f32a0f84110","execution":{"iopub.status.busy":"2024-05-12T20:58:00.493643Z","iopub.execute_input":"2024-05-12T20:58:00.494392Z","iopub.status.idle":"2024-05-12T20:58:12.990973Z","shell.execute_reply.started":"2024-05-12T20:58:00.494355Z","shell.execute_reply":"2024-05-12T20:58:12.989553Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m         target_batch \u001b[38;5;241m=\u001b[39m target_batch\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     20\u001b[0m         target_batch \u001b[38;5;241m=\u001b[39m target_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 22\u001b[0m         output_batch \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m         output_batch \u001b[38;5;241m=\u001b[39m output_batch[\u001b[38;5;241m2\u001b[39m, :, :,:]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#         loss = loss_function(output_batch, target_batch)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchaudio/models/_hdemucs.py:615\u001b[0m, in \u001b[0;36mHDemucs.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m             skip \u001b[38;5;241m=\u001b[39m saved_t\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 615\u001b[0m             xt, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtdec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(saved) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved is not empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchaudio/models/_hdemucs.py:281\u001b[0m, in \u001b[0;36m_HDecLayer.forward\u001b[0;34m(self, x, skip, length)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    280\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m skip\n\u001b[0;32m--> 281\u001b[0m     y \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mglu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     y \u001b[38;5;241m=\u001b[39m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 41.06 MiB is free. Process 2733 has 14.71 GiB memory in use. Of the allocated memory 14.30 GiB is allocated by PyTorch, and 276.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 41.06 MiB is free. Process 2733 has 14.71 GiB memory in use. Of the allocated memory 14.30 GiB is allocated by PyTorch, and 276.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}